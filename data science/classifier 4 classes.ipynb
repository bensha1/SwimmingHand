{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf #tf version 2.1.1\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tinymlgen import port\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "import pickle\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hand_model_classifier(data,epoch_count, neurons):\n",
    "    \"\"\"\n",
    "    Gets a labled dataset with measurments classified into 4 classes, the number of epochs to train and number of neurons per layer.\n",
    "    Returns a classifier model trained with the first 70% of measurements and tested with the next 15%.\n",
    "    \"\"\"\n",
    "    inp, output = [], []\n",
    "    for tup in data:\n",
    "        try:\n",
    "            inp.append((tup[0],tup[1], tup[2],tup[3], tup[4],tup[5]))\n",
    "            output.append(tup[6])\n",
    "        except:\n",
    "            print(\"problem tuple\")\n",
    "            pass\n",
    "    size = min(len(inp), len(output))\n",
    "    in1 = np.array(inp[:size])\n",
    "    out = np.array(output[:size])\n",
    "\n",
    "    # split into train, validation, test\n",
    "    TRAIN_SPLIT =  int(0.6 * size)\n",
    "    TEST_SPLIT = int(0.2 * size + TRAIN_SPLIT)\n",
    "    x_train, x_test, x_validate = np.split(in1, [TRAIN_SPLIT, TEST_SPLIT])\n",
    "    y_train, y_test, y_validate = np.split(out, [TRAIN_SPLIT, TEST_SPLIT])\n",
    "\n",
    "    # create a NN with 3 layers of neurons\n",
    "    model = Sequential([\n",
    "    Dense(neurons, activation='relu', input_shape=(6,)),\n",
    "    Dense(neurons, activation='relu'),\n",
    "    Dense(neurons/2, activation='relu'),\n",
    "    Dense(4, activation=tf.nn.softmax)\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=Adam(),\n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "    model.fit(x_train, y_train, verbose=0, epochs=epoch_count, batch_size=16,\n",
    "                        validation_data=(x_validate, y_validate))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(path = r\"C:\\Users\\Nadav\\Downloads\\log14-6_angle_{}.pkl\"):\n",
    "    \"\"\"\n",
    "    Function that takes a path to a folder with pickle files of measurements in four positions.\n",
    "    The files named by the angles of the measurement angle as can be seen in the dataset folder on github.\n",
    "    Returns a shuffled list of lists with the 2 sesnor meassurements and the label.\n",
    "    \"\"\"\n",
    "    labled_data = []\n",
    "    min_length = 100000\n",
    "    for label in [0, 90, 180, 270]:\n",
    "        with open(path.format(label), \"rb\") as f: \n",
    "            data = pickle.load(f)\n",
    "            if len(data) < min_length:\n",
    "                min_length = len(data)\n",
    "    for label in [0, 90, 180, 270]:\n",
    "        i = 0\n",
    "        with open(path.format(label), \"rb\") as f: \n",
    "            data = pickle.load(f)\n",
    "            for tup in data:\n",
    "                unlabled = list(tup[1:])\n",
    "                unlabled.append(int(label/90))\n",
    "                labled_data.append(unlabled)\n",
    "                i += 1\n",
    "                if (i == min_length):\n",
    "                    break\n",
    "    random.shuffle(labled_data)\n",
    "    return labled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_fit(tup):\n",
    "    \"\"\"\n",
    "    Gets a tuple created by the model prediction and returns the index of the best fitting class.\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    index = 0\n",
    "    max_val = -math.inf\n",
    "    while (i < 4):\n",
    "        if (tup[i] > max_val):\n",
    "            index = i\n",
    "            max_val = tup[i]\n",
    "        i += 1\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(model, test_data):\n",
    "    \"\"\"\n",
    "    Gets a model and the raw data and uses the last 15% of entries as a validation set to check the accuracy.\n",
    "    Returns the percentage of correct predictions.\n",
    "    \"\"\"\n",
    "    inp, output = [], []\n",
    "    for tup in test_data:\n",
    "        try:\n",
    "            inp.append((tup[0], tup[1],tup[2],tup[3], tup[4],tup[5]))\n",
    "            output.append(tup[6])\n",
    "        except:\n",
    "            print(\"problem tuple\")\n",
    "            pass\n",
    "    size = min(len(inp), len(output))\n",
    "    in1 = np.array(inp[:size])\n",
    "    out = np.array(output[:size])\n",
    "\n",
    "    # split into train, validation, test\n",
    "    TRAIN_SPLIT =  int(0.7 * size)\n",
    "    TEST_SPLIT = int(0.15 * size + TRAIN_SPLIT)\n",
    "    x_train, x_test, x_validate = np.split(in1, [TRAIN_SPLIT, TEST_SPLIT])\n",
    "    y_train, y_test, y_validate = np.split(out, [TRAIN_SPLIT, TEST_SPLIT])\n",
    "    \n",
    "    tries = 0.0\n",
    "    num_correct = 0.0\n",
    "    \n",
    "    for i in range(len(x_validate)):\n",
    "        pred = model.predict(np.array([(x_validate[i][0],x_validate[i][1],x_validate[i][2],x_validate[i][3],x_validate[i][4],x_validate[i][5])]))[0]\n",
    "        res = best_fit(pred)\n",
    "        tries += 1\n",
    "        if (res == y_validate[i]):\n",
    "            num_correct += 1\n",
    "    percent_correct = num_correct/tries*100\n",
    "    print(\"percent correct: {}\".format(percent_correct))\n",
    "    return percent_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percent correct: 42.87812041116006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24969"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def main():\n",
    "    labled = create_data()\n",
    "    model = hand_model_classifier(labled, 100, 16)\n",
    "    c_code = port(model, pretty_print=True).replace(\"model_data\", \"hand_model\")\n",
    "    model_str = \"model_{}_{}_{}_classifier4_acc_{}\".format(0, 100, 16, int (error(model, labled)))\n",
    "    open(r\"C:\\Users\\Nadav\\Documents\\IoT project\\models\\{}.h\".format(model_str), \"w\").write(c_code) # hard coded path should be manually changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
